# Tokenomics Lab - Robots.txt
# https://tokenomicslab.com

# Allow all crawlers
User-agent: *
Allow: /

# Disallow admin and private areas
Disallow: /admin/
Disallow: /api/
Disallow: /dashboard
Disallow: /premium/
Disallow: /profile

# Disallow authentication pages
Disallow: /login
Disallow: /signup

# Allow public pages
Allow: /
Allow: /docs
Allow: /docs/algorithm
Allow: /pricing
Allow: /contact
Allow: /privacy
Allow: /terms

# Crawl delay (optional - adjust as needed)
Crawl-delay: 1

# Sitemap location
Sitemap: https://tokenomicslab.com/sitemap.xml

# Specific bot rules
User-agent: Googlebot
Allow: /
Disallow: /admin/
Disallow: /api/
Disallow: /dashboard
Disallow: /premium/

User-agent: Bingbot
Allow: /
Disallow: /admin/
Disallow: /api/
Disallow: /dashboard
Disallow: /premium/

# Block bad bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# Block AI scrapers (optional - uncomment if needed)
# User-agent: GPTBot
# Disallow: /

# User-agent: ChatGPT-User
# Disallow: /

# User-agent: CCBot
# Disallow: /

# User-agent: anthropic-ai
# Disallow: /

# User-agent: Claude-Web
# Disallow: /
